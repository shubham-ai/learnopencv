{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2454d9ba-9db4-4b37-98e8-201ba285c92f",
   "metadata": {
    "id": "2454d9ba-9db4-4b37-98e8-201ba285c92f"
   },
   "source": [
    "## Setup\n",
    "Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f3a4d-a914-42cb-b0b6-be84a84e5e41",
   "metadata": {
    "id": "433f3a4d-a914-42cb-b0b6-be84a84e5e41"
   },
   "outputs": [],
   "source": [
    "%pip install ultralytics[explorer] openai\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae602549-3419-4909-9f82-35cba515483f",
   "metadata": {
    "id": "ae602549-3419-4909-9f82-35cba515483f"
   },
   "outputs": [],
   "source": [
    "from ultralytics import Explorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba492b2e-7c57-4ebd-a24d-746d349ac642",
   "metadata": {},
   "source": [
    "## Fine Tuning with Custom Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a77d9e-3484-4c8f-9a41-4168e65c5a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your model\n",
    "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data='path/to/your/data.yaml', epochs=100, imgsz=640, batch=32, save=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c06350-be8e-45cf-b3a6-b5017bbd943c",
   "metadata": {
    "id": "d8c06350-be8e-45cf-b3a6-b5017bbd943c"
   },
   "source": [
    "## 1. Similarity search\n",
    "Utilize the power of vector similarity search to find the similar data points in your dataset along with their distance in the embedding space. Simply create an embeddings table for the given dataset-model pair. It is only needed once and it is reused automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334619da-6deb-4b32-9fe0-74e0a79cee20",
   "metadata": {
    "id": "334619da-6deb-4b32-9fe0-74e0a79cee20"
   },
   "outputs": [],
   "source": [
    "exp = Explorer(\"path/to/your.yaml\", model=\"path/to/your/model.pt\")\n",
    "exp.create_embeddings_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c5e42d-bc7e-4b4c-bde0-643072a2165d",
   "metadata": {
    "id": "b6c5e42d-bc7e-4b4c-bde0-643072a2165d"
   },
   "source": [
    "One the embeddings table is built, you can get run semantic search in any of the following ways:\n",
    "- On a given index / list of indices in the dataset like - `exp.get_similar(idx=[1,10], limit=10)`\n",
    "- On any image/ list of images not in the dataset  - `exp.get_similar(img=[\"path/to/img1\", \"path/to/img2\"], limit=10)`\n",
    "In case of multiple inputs, the aggregade of their embeddings is used.\n",
    "\n",
    "You get a pandas dataframe with the `limit` number of most similar data points to the input, along with their distance in the embedding space. You can use this dataset to perform further filtering\n",
    "<img width=\"1120\" alt=\"Screenshot 2024-01-06 at 9 45 42 PM\" src=\"https://learnopencv.com/wp-content/uploads/2024/03/image4.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b485f05b-d92d-42bc-8da7-5e361667b341",
   "metadata": {
    "id": "b485f05b-d92d-42bc-8da7-5e361667b341"
   },
   "outputs": [],
   "source": [
    "similar = exp.get_similar(idx=1, limit=10)\n",
    "similar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf4b489-2161-4176-a1fe-d1d067d8083d",
   "metadata": {
    "id": "acf4b489-2161-4176-a1fe-d1d067d8083d"
   },
   "source": [
    "You can use the also plot the similar samples directly using the `plot_similar` util\n",
    "<p>\n",
    "\n",
    " <img src=\"https://learnopencv.com/wp-content/uploads/2024/03/image9.png\" />\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0677e0e-36bb-4322-87af-87f57bb491ea",
   "metadata": {},
   "source": [
    " ### Plot list of idxs or imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbfe7d0-8613-4529-adb6-6e0632d7cce7",
   "metadata": {
    "id": "9dbfe7d0-8613-4529-adb6-6e0632d7cce7"
   },
   "outputs": [],
   "source": [
    "exp.plot_similar(idx=6500, limit=20)\n",
    "#exp.plot_similar(idx=[100,101], limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8058a73a-a699-433f-bc75-4caf25c3a693",
   "metadata": {},
   "source": [
    "### Plot any external images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260e09bf-4960-4089-a676-cb0e76ff3c0d",
   "metadata": {
    "id": "260e09bf-4960-4089-a676-cb0e76ff3c0d"
   },
   "outputs": [],
   "source": [
    "exp.plot_similar(img=\"https://learnopencv.com/wp-content/uploads/2024/03/rhino-test.jpg\", limit=10, labels=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cea63f1-71f1-46da-af2b-b1b7d8f73553",
   "metadata": {
    "id": "0cea63f1-71f1-46da-af2b-b1b7d8f73553"
   },
   "source": [
    "## 2. Ask AI: Search or filter with Natural Language\n",
    "You can prompt the Explorer object with the kind of data points you want to see, and it'll try to return a dataframe with those. Because LLMs power it, it doesn't always get it right. In that case, it'll return None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fb92ac-7f76-465a-a9ba-ea7492498d9c",
   "metadata": {
    "id": "92fb92ac-7f76-465a-a9ba-ea7492498d9c"
   },
   "outputs": [],
   "source": [
    "df = exp.ask_ai(\"show me images containing more than 10 objects with at least 2 persons\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a7d26e-0ce5-4578-ad1a-b1253805280f",
   "metadata": {
    "id": "f2a7d26e-0ce5-4578-ad1a-b1253805280f"
   },
   "source": [
    "for plotting these results you can use `plot_query_result` util\n",
    "Example:\n",
    "```\n",
    "plt = plot_query_result(exp.ask_ai(\"show me 10 images containing exactly 2 persons\"))\n",
    "Image.fromarray(plt)\n",
    "```\n",
    "<p>\n",
    "    <img src=\"https://github.com/AyushExel/assets/assets/15766192/2cb780de-d05b-4412-a526-7f7f0f10e669\">\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72a8306-12c4-4fd3-b586-3b8b4cf653b5",
   "metadata": {},
   "source": [
    "### Plot AI Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cfab84-9835-4da0-8e9a-42b30cf84511",
   "metadata": {
    "id": "b1cfab84-9835-4da0-8e9a-42b30cf84511"
   },
   "outputs": [],
   "source": [
    "from ultralytics.data.explorer import plot_query_result\n",
    "from PIL import Image\n",
    "\n",
    "plt = plot_query_result(exp.ask_ai(\"show me 10 images containing exactly 2 persons\"))\n",
    "Image.fromarray(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35315ae6-d827-40e4-8813-279f97a83b34",
   "metadata": {
    "id": "35315ae6-d827-40e4-8813-279f97a83b34"
   },
   "source": [
    "## 3. Run SQL queries on your Dataset!\n",
    "Sometimes you might want to investigate a certain type of entries in your dataset. For this Explorer allows you to execute SQL queries.\n",
    "It accepts either of the formats:\n",
    "- Queries beginning with \"WHERE\" will automatically select all columns. This can be thought of as a short-hand query\n",
    "- You can also write full queries where you can specify which columns to select\n",
    "\n",
    "This can be used to investigate model performance and specific data points. For example:\n",
    "- let's say your model struggles on images that have humans and dogs. You can write a query like this to select the points that have at least 2 humans AND at least one dog.\n",
    "\n",
    "You can combine SQL query and semantic search to filter down to specific type of results\n",
    "<img width=\"994\" alt=\"Screenshot 2024-01-06 at 9 47 30 PM\" src=\"https://learnopencv.com/wp-content/uploads/2024/03/image15.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b17e32-65ae-45fd-9eb1-f527238b1b94",
   "metadata": {},
   "source": [
    "### Plot SQL Queries\n",
    "Just like similarity search, you also get a util to directly plot the sql queries using `exp.plot_sql_query`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd1072f-3100-4331-a0e3-4e2f6b1005bf",
   "metadata": {
    "id": "8cd1072f-3100-4331-a0e3-4e2f6b1005bf"
   },
   "outputs": [],
   "source": [
    "table = exp.sql_query(\"WHERE labels LIKE '%rhino%' AND labels LIKE '%elephant%' LIMIT 10\")\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b977e7-d048-4b22-b8c4-084a03b04f23",
   "metadata": {
    "id": "18b977e7-d048-4b22-b8c4-084a03b04f23"
   },
   "outputs": [],
   "source": [
    "exp.plot_sql_query(\"WHERE labels LIKE '%person, person%' AND labels LIKE '%dog%' LIMIT 10\", labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c843c23-e3f2-490e-8d6c-212fa038a149",
   "metadata": {
    "id": "1c843c23-e3f2-490e-8d6c-212fa038a149"
   },
   "source": [
    "## 4. Similarity Index\n",
    "Here's a simple example of an operation powered by the embeddings table. Explorer comes with a `similarity_index` operation-\n",
    "* It tries to estimate how similar each data point is with the rest of the dataset.\n",
    "*  It does that by counting how many image embeddings lie closer than `max_dist` to the current image in the generated embedding space, considering `top_k` similar images at a time.\n",
    "\n",
    "For a given dataset, model, `max_dist` & `top_k` the similarity index once generated will be reused. In case, your dataset has changed, or you simply need to regenerate the similarity index, you can pass `force=True`.\n",
    "Similar to vector and SQL search, this also comes with a util to directly plot it. Let's look at the plot first\n",
    "<img width=\"633\" alt=\"Screenshot 2024-01-06 at 9 49 36 PM\" src=\"https://github.com/AyushExel/assets/assets/15766192/96a9d984-4a72-4784-ace1-428676ee2bdd\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953c2a5f-1b61-4acf-a8e4-ed08547dbafc",
   "metadata": {
    "id": "953c2a5f-1b61-4acf-a8e4-ed08547dbafc"
   },
   "outputs": [],
   "source": [
    "exp.plot_similarity_index(max_dist=0.2, top_k=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28228a9a-b727-45b5-8ca7-8db662c0b937",
   "metadata": {
    "id": "28228a9a-b727-45b5-8ca7-8db662c0b937"
   },
   "source": [
    "Now let's look at the output of the operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4161aaa-20e6-4df0-8e87-d2293ee0530a",
   "metadata": {
    "id": "f4161aaa-20e6-4df0-8e87-d2293ee0530a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sim_idx = exp.similarity_index(max_dist=0.2, top_k=0.01, force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01d5b1a-9adb-4c3c-a873-217c71527c8d",
   "metadata": {
    "id": "b01d5b1a-9adb-4c3c-a873-217c71527c8d"
   },
   "outputs": [],
   "source": [
    "sim_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b28e54-4fbb-400e-ad8c-7068cbba11c4",
   "metadata": {
    "id": "22b28e54-4fbb-400e-ad8c-7068cbba11c4"
   },
   "source": [
    "Let's create a query to see what data points have similarity count of more than 30 and plot images similar to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d2557b-d401-43cf-937d-4f554c7bc808",
   "metadata": {
    "id": "58d2557b-d401-43cf-937d-4f554c7bc808"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sim_count = np.array(sim_idx[\"count\"])\n",
    "sim_idx['im_file'][sim_count > 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ec8d76-271a-41ab-ac74-cf8c0084ba5e",
   "metadata": {
    "id": "a5ec8d76-271a-41ab-ac74-cf8c0084ba5e"
   },
   "source": [
    "You should see something like this\n",
    "\n",
    "<img src=\"https://learnopencv.com/wp-content/uploads/2024/03/image1.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff081f9-3bb7-466b-bf9f-a2c464804c2d",
   "metadata": {},
   "source": [
    "### Using avg embeddings of 2 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7b2ee3-9f35-48a2-9c38-38379516f4d2",
   "metadata": {
    "id": "3a7b2ee3-9f35-48a2-9c38-38379516f4d2"
   },
   "outputs": [],
   "source": [
    "exp.plot_similar(idx=[7146, 14035]) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
