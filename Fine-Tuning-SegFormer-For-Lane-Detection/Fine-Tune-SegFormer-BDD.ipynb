{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0633eae0-179c-4ab1-9456-caca00989fad",
   "metadata": {},
   "source": [
    "### Code written by Pranav Durai \n",
    "### Fine-Tuning SegFormer for Improved Lane Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f988b40f-8ba6-4da5-8880-070e90a27db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "from torchvision import transforms as TF\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "from transformers import get_scheduler\n",
    "\n",
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(url, local_filename):\n",
    "\n",
    "    # Update Dropbox link to force download\n",
    "    if \"www.dropbox.com\" in url and \"?dl=0\" in url:\n",
    "        url = url.replace(\"?dl=0\", \"?dl=1\")\n",
    "    \n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Write the content of the response to a file\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"File downloaded and saved as {local_filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to download file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download 10% sample of BDD100K Dataset\n",
    "download_dataset('https://www.dropbox.com/scl/fi/40onxgztkbtqxvsg2d6fk/deep_drive_10K.zip?rlkey=8h098tbe9dry81jidtte1d9j5&dl=1', 'BDD.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "927c1728-295d-4985-bfc0-57980d6b2e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BDDDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.transform = transform\n",
    "        self.images = [img for img in os.listdir(images_dir) if img.endswith('.jpg')]\n",
    "        self.masks = [mask.replace('.jpg', '.png') for mask in self.images]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.images_dir, self.images[idx])\n",
    "        mask_path = os.path.join(self.masks_dir, self.masks[idx])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert('L')  # Convert mask to grayscale\n",
    "        \n",
    "        # Convert mask to binary format with 0 and 1 values\n",
    "        mask = np.array(mask)\n",
    "        mask = (mask > 0).astype(np.uint8)  # Assuming non-zero pixels are lanes\n",
    "        \n",
    "        # Convert to PIL Image for consistency in transforms\n",
    "        mask = Image.fromarray(mask)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            # Assuming to_tensor transform is included which scales pixel values between 0-1\n",
    "            # mask = to_tensor(mask)  # Convert the mask to [0, 1] range\n",
    "        mask = TF.functional.resize(img=mask, size=[360, 640], interpolation=Image.NEAREST)\n",
    "        mask = TF.functional.to_tensor(mask)\n",
    "        mask = (mask > 0).long()  # Threshold back to binary and convert to LongTensor\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "def mean_iou(preds, labels, num_classes):\n",
    "    # Flatten predictions and labels\n",
    "    preds_flat = preds.view(-1)\n",
    "    labels_flat = labels.view(-1)\n",
    "\n",
    "    # Check that the number of elements in the flattened predictions\n",
    "    # and labels are equal\n",
    "    if preds_flat.shape[0] != labels_flat.shape[0]:\n",
    "        raise ValueError(f\"Predictions and labels have mismatched shapes: \"\n",
    "                         f\"{preds_flat.shape} vs {labels_flat.shape}\")\n",
    "\n",
    "    # Calculate the Jaccard score for each class\n",
    "    iou = jaccard_score(labels_flat.cpu().numpy(), preds_flat.cpu().numpy(),\n",
    "                        average=None, labels=range(num_classes))\n",
    "\n",
    "    # Return the mean IoU\n",
    "    return np.mean(iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef43d5f1-4663-420d-bad9-96f30c291035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the appropriate transformations\n",
    "transform = TF.Compose([\n",
    "    TF.Resize((360, 640)),\n",
    "    TF.ToTensor(),\n",
    "    TF.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create the dataset\n",
    "train_dataset = BDDDataset(images_dir='deep_drive_10K/train/images',\n",
    "                           masks_dir='deep_drive_10K/train/masks',\n",
    "                           transform=transform)\n",
    "\n",
    "valid_dataset = BDDDataset(images_dir='deep_drive_10K/valid/images',\n",
    "                           masks_dir='deep_drive_10K/valid/masks',\n",
    "                           transform=transform)\n",
    "\n",
    "# Create the data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=6)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73f48c2a-f53a-494c-a6de-6d00cc93c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "model = SegformerForSemanticSegmentation.from_pretrained('nvidia/segformer-b2-finetuned-ade-512-512')\n",
    "\n",
    "# Adjust the number of classes for BDD dataset\n",
    "model.config.num_labels = 2  # Replace with the actual number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "009b29eb-64c8-4755-b0b9-ef81503e53f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for CUDA acceleration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffa2aa2-bb21-41e1-9fd5-f96f269d358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "num_epochs = 30\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# Placeholder for best mean IoU and best model weights\n",
    "best_iou = 0.0\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_iterator = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\")\n",
    "    for batch in train_iterator:\n",
    "        images, masks = batch\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device).long()  # Ensure masks are LongTensors\n",
    "\n",
    "        # Remove the channel dimension from the masks tensor\n",
    "        masks = masks.squeeze(1)  # This changes the shape from [batch, 1, H, W] to [batch, H, W]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Pass pixel_values and labels to the model\n",
    "        outputs = model(pixel_values=images, labels=masks,return_dict=True)\n",
    "        \n",
    "        loss = outputs[\"loss\"]\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        outputs = F.interpolate(outputs[\"logits\"], size=masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        \n",
    "        train_iterator.set_postfix(loss=loss.item())\n",
    "    \n",
    "    # Evaluation loop for each epoch\n",
    "    model.eval()\n",
    "    total_iou = 0\n",
    "    num_batches = 0\n",
    "    valid_iterator = tqdm(valid_loader, desc=\"Validation\", unit=\"batch\")\n",
    "    for batch in valid_iterator:\n",
    "        images, masks = batch\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device).long()\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            # Get the logits from the model and apply argmax to get the predictions\n",
    "            outputs = model(pixel_values=images,return_dict=True)\n",
    "            outputs = F.interpolate(outputs[\"logits\"], size=masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            preds = torch.unsqueeze(preds, dim=1)\n",
    "\n",
    "        preds = preds.view(-1)\n",
    "        masks = masks.view(-1)\n",
    "    \n",
    "        # Compute IoU\n",
    "        iou = mean_iou(preds, masks, model.config.num_labels)\n",
    "        total_iou += iou\n",
    "        num_batches += 1\n",
    "        valid_iterator.set_postfix(mean_iou=iou)\n",
    "    \n",
    "    epoch_iou = total_iou / num_batches\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Mean IoU: {epoch_iou:.4f}\")\n",
    "\n",
    "    # Check for improvement\n",
    "    if epoch_iou > best_iou:\n",
    "        print(f\"Validation IoU improved from {best_iou:.4f} to {epoch_iou:.4f}\")\n",
    "        best_iou = epoch_iou\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_wts, 'best_model.pth')\n",
    "\n",
    "# After all epochs, load the best model weights - optional\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "print(\"Loaded the best model weights!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
